{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "from os import path\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prince_data_utils.photo_nuclear as ppn\n",
    "import prince_data_utils.photon_fields as ppf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['EBL_models', 'photo_nuclear']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5fname = 'prince_db_05.h5'\n",
    "try:\n",
    "    prince_db.close()\n",
    "except:\n",
    "    pass\n",
    "output_dir = path.abspath('.')\n",
    "#exclusively create the file\n",
    "if path.isfile(path.join(output_dir,h5fname)):\n",
    "    os.unlink(path.join(output_dir,h5fname))\n",
    "prince_db = h5py.File(path.join(output_dir,h5fname),'x')\n",
    "prince_db.attrs['created_on'] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "prince_db.attrs['version'] = '0.5.0'\n",
    "# Make groups for different types of data required by MCEq.\n",
    "for grp_name in [\"photo_nuclear\", \"EBL_models\"]:\n",
    "    prince_db.create_group(grp_name)\n",
    "prince_db.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store photo-nuclear interaction tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossSectionsFromAscii::_load(): Loading files D:\\OneDrive\\devel\\git\\PriNCe-data-utils\\prince_data_utils\\resources\\photo-nuclear\\CRP2_TALYS_*\n",
      "CrossSectionsFromAscii::_load(): Loading files D:\\OneDrive\\devel\\git\\PriNCe-data-utils\\prince_data_utils\\resources\\photo-nuclear\\PEANUT_IAS_*\n"
     ]
    }
   ],
   "source": [
    "talys = ppn.CrossSectionsFromAscii('CRP2_TALYS')\n",
    "fluka = ppn.CrossSectionsFromAscii('PEANUT_IAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modname, pnmod in [('CRP2_TALYS', talys), ('PEANUT_IAS', fluka)]:\n",
    "    hdf_group = prince_db[\"photo_nuclear\"].create_group(modname)\n",
    "    hdf_group.create_dataset('energy_grid', data=pnmod.energy_grid,\n",
    "        chunks=True, compression=\"lzf\", shuffle=True)\n",
    "    hdf_group.create_dataset('inel_mothers', data=pnmod.inel_mothers,\n",
    "        chunks=True, compression=\"lzf\", shuffle=True)\n",
    "    hdf_group.create_dataset('mothers_daughters', data=pnmod.mothers_daughters,\n",
    "        chunks=True, compression=\"lzf\", shuffle=True)\n",
    "    hdf_group.create_dataset('inelastic_cross_sctions', data=pnmod.inelastic_cross_sctions,\n",
    "        chunks=True, compression=\"lzf\", shuffle=True)\n",
    "    hdf_group.create_dataset('fragment_yields', data=pnmod.fragment_yields,\n",
    "        chunks=True, compression=\"lzf\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['EBL_models', 'photo_nuclear']>\n",
      "<KeysViewHDF5 ['CRP2_TALYS', 'PEANUT_IAS']>\n",
      "<KeysViewHDF5 ['energy_grid', 'fragment_yields', 'inel_mothers', 'inelastic_cross_sctions', 'mothers_daughters']>\n"
     ]
    }
   ],
   "source": [
    "print(prince_db.keys())\n",
    "print(prince_db['photo_nuclear'].keys())\n",
    "print(prince_db['photo_nuclear']['CRP2_TALYS'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store EBL photon field arrays (for spline construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ebl_obj in [ppf.Francescini2008(), ppf.Inoue2013(),\n",
    "                ppf.Gilmore2011(), ppf.Dominguez2010()]:\n",
    "    ebl_gr = prince_db['EBL_models'].create_group(ebl_obj.__class__.__name__)\n",
    "    xyz_d = ebl_obj.get_xyz()\n",
    "    for subset in xyz_d:\n",
    "        sub_gr = ebl_gr.create_group(subset)\n",
    "        sub_gr.create_dataset(\"x\", data=xyz_d[subset][0],\n",
    "        chunks=True, compression=\"lzf\", shuffle=True)\n",
    "        sub_gr.create_dataset(\"y\", data=xyz_d[subset][1],\n",
    "        chunks=True, compression=\"lzf\", shuffle=True)\n",
    "        sub_gr.create_dataset(\"z\", data=xyz_d[subset][2],\n",
    "        chunks=True, compression=\"lzf\", shuffle=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['Dominguez2010', 'Francescini2008', 'Gilmore2011', 'Inoue2013']>\n",
      "<KeysViewHDF5 ['base', 'lower', 'upper']>\n",
      "<KeysViewHDF5 ['x', 'y', 'z']>\n"
     ]
    }
   ],
   "source": [
    "print(prince_db['EBL_models'].keys())\n",
    "print(prince_db['EBL_models']['Dominguez2010'].keys())\n",
    "print(prince_db['EBL_models']['Dominguez2010']['base'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prince_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
